// webppl s2-bda-postcogsci17.wppl --require webppl-json
// requires webppl package: webppl-json

var index = last(process.argv) // load index as last command line index

var utterances = [
  "yes_terrible","yes_bad","yes_good","yes_amazing",
  "not_terrible","not_bad","not_good","not_amazing"
];

var negative_utterances = [
  "not_terrible","not_bad","not_good","not_amazing"
];

var states = [0, 1, 2, 3];

var statePrior = function(){
  return uniformDraw(states);
};

var isNegation = function(utt){
  return (utt.split("_")[0] == "not")
};

var round = function(x){
  return Math.round(x * 100) / 100
}

var weightBins = map(round, _.range(0,1, 0.01))
var phiWeights = repeat(weightBins.length, function(){1})

var goalWeightPrior = Infer({model: function(){
  return uniformDraw(weightBins)
}})

var nBins = weightBins.length;
var kernelWidth = nBins / 4;

var kernelFn = function(prevVal){
  var i = weightBins.indexOf(prevVal);
  var upper = (i + kernelWidth) > nBins ? nBins : i + kernelWidth;
  var lower = (i - kernelWidth) < 0 ? 0 : i - kernelWidth;
  return Categorical({vs: weightBins.slice(lower,upper),
                      ps: phiWeights.slice(lower,upper)})
}

// measured in Experiment 1
var literalSemantics = json.read('data/literal_semantics_3heart_raw.json');
var data = json.read('data/utterance_3heart_registered.json')

var litSemanticsPosteriorObj = _.fromPairs(map(function(u){
  return [u, _.fromPairs(map(function(s){
    var litParams = _.filter(literalSemantics, {state: s, utterance: u})[0]
//     display(litParams)
    return [s, {a: litParams.posterior_b1, b: litParams.posterior_b2}]
  }, states))]
}, utterances))


var goals = _.uniq(_.map(data, "goal"));
var states = _.uniq(_.map(data, "true_state")); // need to create smoothers around these states


var model = function(){

var litSemantics = _.fromPairs(map(function(u){
    return [u, _.fromPairs(map(function(s){
      var litParams = litSemanticsPosteriorObj[u][s];
      return [s, beta(litParams)]
    }, states))]
  }, utterances))

// display(litSemantics.not_terrible)
// 
// var litSemKern = map(function(u){
//       var litParams = litSemantics.u;
//       display(litParams)
//       return sample(litParams, {driftKernel: kernelFn})
//     }, utterances)
// display(litSemKern)
// 

  var RSAparameters = {
    speakerOptimality: uniformDrift({a: 0, b: 20, width:2}),
//     speakerOptimality2: uniformDrift({a:0, b: 10, width: 0.5}),
//     alpha: uniformDrift({a: 0, b: 10, width:0.5}),
    cost: uniformDrift({a: 1, b: 10, width:0.25})
  };

  var cost_yes = 1;
  var uttCosts = map(function(u) {
    return isNegation(u) ? Math.exp(-RSAparameters.cost) : Math.exp(-cost_yes)
  }, utterances)

  var utterancePrior = Infer({model: function(){
    return utterances[discrete(uttCosts)];
  }});

  var meaning = function(words, state){
    return flip(litSemantics[words][state]);
  };

  var listener0 = cache(function(utterance) {
    Infer({method: "enumerate"}, function(){
      var state = uniformDraw(states);
      var m = meaning(utterance, state);
      condition(m);
      return state;
    });
  }, 10000);

  var speaker1 = cache(function(state, speakerGoals) {
    Infer({method: "enumerate"}, function(){
      var utterance = sample(utterancePrior);

      var speakerOptimality = RSAparameters.speakerOptimality;
//       var alpha = RSAparameters.alpha;

      var L0 = listener0(utterance);

      var epistemicUtility = L0.score(state);
//       var socialUtility = expectation(L0, function(s){return alpha*s});
      var socialUtility = expectation(L0, function(s){return s});

      var eUtility = speakerGoals.phi*epistemicUtility;
      var sUtility = (1-speakerGoals.phi)*socialUtility;

      var speakerUtility = eUtility+sUtility;
//     	var speakerUtility = eUtility; //actual(1)

      factor(speakerOptimality*speakerUtility);

      return utterance;
    })
  }, 10000)

  var listener1 = cache(function(utterance) {
    Infer({method: "enumerate"}, function(){

      var speakerGoals = {
        phi:categorical ({vs: weightBins, ps: phiWeights})
      }

      var state = uniformDraw(states);

      var S1 = speaker1(state, speakerGoals)
      observe(S1, utterance)

      return {
        state: state,
        goals: speakerGoals
      }
    })
  }, 10000)

  var speaker2 = cache(function(exptCondInfo) {
    Enumerate(function(){
      var state = exptCondInfo.state;
      var s1Goals = exptCondInfo.goalWeights1;
      var s2Goals = exptCondInfo.goalWeights2;
      var utterance = sample(utterancePrior);
//       var alpha = RSAparameters.alpha;

      var L1 = listener1(utterance)
	  var L1_goal = marginalize(L1, "goals");
	  var L1_state = marginalize(L1, "state");

    var epistemicUtility = L1_state.score(state);
//     var socialUtility = expectation(L1_state, function(s){return alpha*s});
    var socialUtility = expectation(L1_state, function(s){return s});
    var eUtility = s1Goals.phi*epistemicUtility;
    var sUtility = (1-s1Goals.phi)*socialUtility;
    var speakerUtility = eUtility+sUtility;

    var selfEpiUtility = L1.score({"state":state,"goals":s1Goals})
    var selfEUtility = s2Goals.phi*selfEpiUtility;
    var selfSUtility = (1-s2Goals.phi)*socialUtility;
var speakerSelfUtility = selfEUtility+selfSUtility;

   	factor(RSAparameters.speakerOptimality*speakerUtility); // actual(2)
//       factor(RSAparameters.speakerOptimality * L1.score({"state":state, "goals":s1Goals}))
// factor(RSAparameters.speakerOptimality*speakerSelfUtility); // self(2)
//     factor(RSAparameters.speakerOptimality * L1_state.score(state)); // self(3)
//    factor(RSAparameters.speakerOptimality * L1_goal.score(intendedGoals)); // self(4)

      return utterance

    })
  }, 10000)


  var goalWeightsAndPostPred = map(function(goal){

    var goalWeights1 = {
      phi: sample(goalWeightPrior, {driftKernel: kernelFn})
    }
    var goalWeights2 = {
      phi: sample(goalWeightPrior, {driftKernel: kernelFn})
    }

    var postPred = map(function(state){

      var utteranceData = _.filter(data, {true_state: state, goal: goal});

      var exptConditionInfo = {
        state: state,
        utterance: false,
        goalWeights1: goalWeights1,
        goalWeights2: goalWeights2
      };

      //       var RSApredictions = speaker1(exptConditionInfo.state,
      //                                     exptConditionInfo.goalWeights);
      var RSApredictions = speaker2(exptConditionInfo);


      mapData({data: utteranceData}, function(d){
        observe(RSApredictions, d.utterance)
      });

      var postSupport = RSApredictions.support();

      var postPredictive = map(function(u){
        return {
          key: "posteriorPredictive",
          goal: goal,
          state: state,
          utt: u,
          val: Math.exp(RSApredictions.score(u))
        }
      }, postSupport)


      var negEndorsement = sum(map(function(u){
        return Math.exp(RSApredictions.score(u))
      }, negative_utterances))

      return _.flattenDeep([postPredictive, {
        key: "posteriorPredictive",
        goal: goal,
        state: state,
        utt: "negation",
        val: negEndorsement
      }])
      
//       return _.flattenDeep([litSemantics, {
//       	key: "litSem",
//       	goal: "NA", 
//       	state: state, 
//       	utt: u,
//       	val: m
//       }])

    }, states)

    return [
      postPred,
      {key: "phiSelf", goal: goal, state: "NA", utt: "NA", val: goalWeights2.phi}, // FIXME: 
      {key: "phi", goal: goal, state: "NA", utt: "NA", val: goalWeights1.phi}
    ]

  }, goals)

  var returnList = _.flattenDeep([
    goalWeightsAndPostPred,
    litSemantics,
    {key: "speakerOptimality", goal: "NA", utt: "NA", state: "NA", val: RSAparameters.speakerOptimality},
//     {key: "speakerOptimality2", goal: "NA", utt: "NA", state: "NA", val: RSAparameters.speakerOptimality2},
//     {key: "alpha", goal: "NA", utt: "NA", state: "NA", val: RSAparameters.alpha},
    {key: "cost", goal: "NA", utt: "NA", state: "NA", val: RSAparameters.cost}
  ])

  var returnObj = _.fromPairs(map(function(i){
    [i.key + "_" + i.goal + "_" + i.state + "_" + i.utt, i.val]
  }, returnList))

  return returnObj

}



var numSamples = 10000;
var method = "MCMC";
var samples = numSamples;
var burn = numSamples / 2;
var posterior = Infer({model, method, samples, burn, verbose: true})
var filename = 'bda-s2_actual2_3heart_paramAdj-mcmc'+
numSamples+'_burn'+burn+'_chain'+index+'.json'

json.write(filename, posterior)

"output written to " + filename;
