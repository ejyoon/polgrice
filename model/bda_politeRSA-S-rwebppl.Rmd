---
title: "bda-politeRSA-S-rwebppl"
author: "M. H. Tessler, Erica Yoon"
date: "1/9/2017"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(binom)
library(rwebppl)
library(jsonlite)
library(readr)
knitr::opts_chunk$set(echo = TRUE)
library(coda)

# set path to working dir
 # local.path <- "~/Documents/research/polgrice/"
local.path <- "~/Documents/Research/polgrice_GIT/"
#source(paste(local.path, "experiment/data_analysis/markdown/polgrice_S.R", sep=""))

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
# HPDhi<- function(s){
hdi_upper <- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
# HPDlo<- function(s){
hdi_lower <- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
options("scipen"=10)   

```

# Literal semantics data

```{r eval=FALSE}
d.lit <- read.csv(paste(local.path,
                        "experiment/data_analysis/data/literalSemantics_wNeg.csv",
                        sep = ""))
```

Summarize behavioral data (in terms of number of "yes"es)

```{r eval=FALSE}
d.lit.summary <- d.lit %>%
  group_by(state, utterance) %>%
  summarize(k = sum(judgment),
            n = n())
```

## Model

```{r eval=FALSE}
literalSemanticsModel <- '
var n = data[0]["n"]
var k = data[0]["k"]

var literalSemantics = function(){
	var theta = uniform(0,1)
  observe( Binomial({n: n, p: theta}), k )
  return {theta: theta}
}
'
```

Run model, for all sites, states, utterances

```{r eval=FALSE}
# sites <- levels(d.lit.summary$site)
states <- levels(factor(d.lit.summary$state))
utterances <- levels(d.lit.summary$utterance)

litSemantics.results <- data.frame()

  for (st in states){
    for (utt in utterances){
      
      d.lit.pass <- d.lit.summary %>% 
        filter((state == st) & (utterance == utt))
      
      rs <- webppl(literalSemanticsModel,
                   data = d.lit.pass,
                   data_var = "data",
                   inference_opts = list(
                     method = "rejection",
                     samples = 10
                   ),
                   model_var = "literalSemantics",
                   output_format = "samples")
      
      rs.summary <- rs %>%
        # summarize(MAP = estimate_mode(theta),
        #           cred_low = hdi_lower(theta),
        #           cred_upper = hdi_upper(theta)) %>%
        mutate(state = st, utterance = utt)
      
      litSemantics.results <- bind_rows(litSemantics.results,
                                        rs.summary)
      print(utt)
    }
    print(st)
  }

# write.csv(litSemantics.results,paste(local.path,
#                          "model/data/literal_semantics_wNeg_10samples_noMAP.csv",sep=""), # CHANGE FILE NAME AS NEEDED
#           row.names=FALSE)



```

Load literal semantics BDA results

```{r}
# litSemantics.results <- read.csv(paste(local.path, "model/data/literal_semantics_wNeg_10000samples.csv",
litSemantics.results <- read.csv(paste(local.path, "model/data/literal_semantics_wNeg_10000samples_noMAP.csv",
# litSemantics.results <- read.csv(paste(local.path, "model/data/literal_semantics_wNeg_10samples_noMAP.csv",
                                       sep = ""))
```

```{r eval=FALSE}
litSemantics.results.org <- litSemantics.results %>%
    mutate(positivity = factor(as.numeric(grepl("yes", utterance)), 
                             levels = c(0, 1), 
                             labels = c("negative","positive"))) %>%
  mutate(utterance = substring(utterance, 5)) %>%
  mutate(utterance = ordered(utterance, levels = c("terrible", "bad", "okay", "good", "amazing")))

ggplot(data=litSemantics.results.org, 
       aes(x=state, y=MAP, col=utterance, group=utterance)) +
  geom_line() +
  facet_grid(positivity~utterance) +
  geom_errorbar(aes(ymin=cred_low,ymax=cred_upper, width=.1))

```

# production prediction data

```{r}
d.utterance <- read.csv(paste(
  local.path, 
  "experiment/data_analysis/data/speaker.csv"
  , sep="")
)  %>%
    filter(utterance != "NA_NA")
```

```{r eval=FALSE}

d <- d.utterance %>%
  separate(utterance, into = c("positivity", "utterance"), sep = "_") %>%
  mutate(true_state = as.factor(true_state),
         goal = as.factor(goal),
         positivity = as.factor(positivity),
         utterance = as.factor(utterance)
          )


ms2 <- d %>%
  filter(!is.na(positivity), !is.na(utterance)) %>% # why is there NA?
  group_by(true_state, goal) %>%
  summarise(n.total=n())

ms3 <- d %>%
  filter(!is.na(positivity), !is.na(utterance)) %>% # why is there NA?
  group_by(true_state, goal, positivity, utterance) %>%
  summarize(n = n())

ms <- left_join(ms2, ms3) %>%
  group_by(true_state, goal, positivity, utterance) %>%
  summarize(mean = n / n.total,
            ci_lower = binom.bayes(n, n.total)$lower,
            ci_upper = binom.bayes(n, n.total)$upper) 

ms_fake <- cbind(expand.grid(true_state=levels(ms$true_state),goal=levels(ms$goal),positivity=levels(ms$positivity), utterance=levels(ms$utterance)), mean=NA, ci_lower=NA, ci_upper=NA)
  

ms.all <- rbind(data.frame(ms), data.frame(ms_fake))
levels(ms.all$true_state) <- c("1 heart", "2 hearts", "3 hearts", "4 hearts", "5 hearts")
levels(ms.all$goal) <- c("want both", "want to be informative", "want to make listener feel good")
levels(ms.all$positivity) <- c("negation", "no negation")

ggplot(data=ms.all, aes(x=positivity, y=mean, fill=utterance)) +
  geom_bar(stat="identity", position=position_dodge()) +
  facet_grid(goal~true_state) +
  xlab("no negation (It was ~) vs negation (It wasn't ~) ") +
  ylab("proportion chosen") +
  # ggtitle("What would the speaker say given their goals?") +
  geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper),position="dodge") +
  geom_hline(yintercept=.1, lty=2) +
  scale_fill_discrete(guide = guide_legend(title = "word"))


```

Polite RSA: production model

```{r}
pRSA <- '
var utterances = ["yes_terrible","yes_bad","yes_okay","yes_good","yes_amazing",
                  "not_terrible","not_bad","not_okay","not_good","not_amazing"
                  ];

var states = [1,2,3,4,5];
var statePrior = function(){
  return uniformDraw(states);
};

var isNegation = function(utt){
  return (utt.split("_") == "not")
};

var cost_yes = 1;
var uttCosts = function(cost_neg){
  map(function(u) {return isNegation(u) ? Math.exp(-cost_neg) : Math.exp(-cost_yes)},
        utterances)
}

var utterancePrior = function(cost_neg){
  return  utterances[discrete(uttCosts(cost_neg))];
};

// measured in Experiment 1
var literalSemantics = dataFromR.literalSemantics;

var litSemanticsPosteriorObj = _.object(map(function(u){
  return [u, _.object(map(function(s){
    [s, _.pluck(_.where(literalSemantics, {state: s, utterance: u}), "theta")]
}, states))]
}, utterances))
// e.g. {"amazing": { 1: [w1, w2, ... , wn], 2: [ ... ], ... }, "terrible": {1: [, ...]} }

var phiWeights = [1,1,1,1,1,1,1,1,1]
var honestyWeights = [1,1,1,1,1]
var kindnessWeights = [1,1,1,1,1]

var meaning = function(literalSemantics, words, state){
  return flip(literalSemantics[words][state]);
}; 

var listener0 = cache(function(literalSemantics, utterance) {
  Infer({method: "enumerate"}, function(){
    var state = statePrior();
    var m = meaning(literalSemantics, utterance, state);
    condition(m);
    return state;
  });

}, 100);

var speaker1 = cache(function(literalSemantics, exptCondInfo, rsaParameters) {
//var speaker1 = cache(function(phi, rsaParameters) {
  Infer({method: "enumerate"}, function(){
    var state = exptCondInfo.state;
    var speakerGoals = exptCondInfo.goalWeights;
    var utterance = utterancePrior(rsaParameters.cost);

    var speakerOptimality = rsaParameters.speakerOptimality;
    var alpha = rsaParameters.alpha;

//    var utterance = utterancePrior(rsaParameters.cost);
    var L0 = listener0(literalSemantics, utterance);
    
    var epistemicUtility = L0.score(state);
    var socialUtility = expectation(L0, function(s){return alpha*s});
    
    var eUtility = speakerGoals.phi*epistemicUtility;
    var sUtility = (1-speakerGoals.phi)*socialUtility;

    var speakerUtility = eUtility+sUtility;

    factor(speakerOptimality*speakerUtility);
    
    return utterance;
  })
}, 100)

var listener1 = cache(function(utterance, literalSemantics, exptCondInfo, rsaParameters) {
 Infer({method: "enumerate"}, function(){
   var speakerGoals = {
     phi: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9][discrete(phiWeights)]
   }
   
   var state = statePrior()
   
   var S1 = speaker1(literalSemantics, exptCondInfo, rsaParameters)

   observe(S1, utterance)

   return {
     state: state,
     goals: speakerGoals
   }
     })
}, 10)

var speaker2 = cache(function(literalSemantics, exptCondInfo, rsaParameters) {
 Enumerate(function(){
   var state = exptCondInfo.state;
   var intendedGoals = exptCondInfo.goalWeights;
   var utterance = utterancePrior(rsaParameters.cost);

   var L1 = listener1(utterance, literalSemantics, exptCondInfo, rsaParameters)

   //FIXME: (1) FACTOR BASED ON STATE AND GOALS (2) FACTOR BASED ON GOALS ONLY
   factor(L1.score({"state":state, "goals":intendedGoals}))
   // factor(L1.score({"goals":intendedGoals}))
   return utterance

 })
}, 10)


'
```


Data analysis model

```{r}
dataAnalysisModel <- '
// foreach helper function
var foreach = function(fn, lst) {
  var foreach_ = function(i) {
    if (i < lst.length) {
      fn(lst[i]);
      foreach_(i + 1);
    }
  };
  foreach_(0);
};
//
  
  var data = dataFromR.data;
  
  var goals = _.uniq(_.pluck(data, "goal"));

  var states = _.uniq(_.pluck(data, "true_state"));
  // var utterances = _.uniq(_.pluck(data, "utterance"));
  
  var dataAnalysis = function(){
    
  var litSemantics = _.object(map(function(u){
	return [u, _.object(map(function(s){
    [s, uniformDraw(litSemanticsPosteriorObj[u][s])]
  }, states))]
}, utterances))

    var RSAparameters = {
      speakerOptimality: uniformDrift({a: 0, b: 20, width:2}),
      alpha: uniformDrift({a: 0, b: 5, width:0.5}),
      cost: uniformDrift({a: 1, b: 10, width:0.25})
    };

    var goalWeightsAndPostPred = map(function(goal){
      
      var goalWeights = {
	      //phi: uniformDrift({a: 0, b: 1, width:0.2})
      phi: uniformDraw([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
	      //honesty: uniformDrift({a: 0, b: 1, width:0.2}), 
	      //kindness: uniformDrift({a: 0, b: 1, width:0.2})
      //honesty: uniformDraw([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),
      //kindness: uniformDraw([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    }

      var postPred = map(function(state){
        
      var utteranceData = _.pluck(_.where(data, {true_state: state, goal: goal}), "utterance"); 

        var exptConditionInfo = {
          state: state, 
          utterance: false,
          goalWeights: goalWeights
        };

        var literalSemantics = litSemantics;
        
        //var RSApredictions = speaker1(literalSemantics, exptConditionInfo, RSAparameters);
        var RSApredictions = speaker2(literalSemantics, exptConditionInfo, RSAparameters);
       //RSApredictions.support()

        mapData({data: utteranceData}, 
            function(d){ 
                // display(RSApredictions.score(d))
                //display("d = " + d +  " ___ scr = " + RSApredictions.score(d) )
                observe(RSApredictions, d) 
            });
        // mapData({data: utteranceData}, function(d){ observe(linkedRSA, d) });
        
        var postSupport = RSApredictions.support(); // all utterances in the posterior

        var postPredictive = map(function(u){
          return {
            key: "posteriorPredictive",
            goal: goal,
            state: state,
            utt: u,
            val: Math.exp(RSApredictions.score(u))
          }
        }, postSupport)

      var negative_utterances = [
                  "not_terrible","not_bad","not_okay","not_good","not_amazing"
      ]

        var negEndorsement = sum(map(function(u){
            return Math.exp(RSApredictions.score(u))
        }, negative_utterances))
        
        return _.flatten([postPredictive, {
            key: "posteriorPredictive",
            goal: goal,
            state: state,
            utt: "negation",
            val: negEndorsement
          }])
        
      }, states)

      return [postPred, 
              {key: "phi", goal: goal, state: "NA", utt: "NA", val: goalWeights.phi},
              //{key: "weightHonest", goal: goal, state: "NA", utt: "NA", val: goalWeights.honesty},
              //{key: "weightKind", goal: goal, state: "NA", utt: "NA", val: goalWeights.kindness}
              ]
      
    }, goals)

    var returnList = _.flatten([goalWeightsAndPostPred, 
                                //litSemantics,
                                {key: "speakerOptimality", goal: "NA", utt: "NA", state: "NA", val: RSAparameters.speakerOptimality},
                                {key: "alpha", goal: "NA", utt: "NA", state: "NA", val: RSAparameters.alpha},
                                {key: "cost", goal: "NA", utt: "NA", state: "NA", val: RSAparameters.cost}
                                ])
    
    var returnObj = _.object(map(function(i){
      [i.key + "_" + i.goal + "_" + i.state + "_" + i.utt, i.val]
    }, returnList))

    return returnObj
    
  }

    
'
```


Run Full BDA model

```{r}
bda.utterance.results <- data.frame()

fullModel <- paste(pRSA, dataAnalysisModel, sep = "\n")

# for (si in sites) {

  # site.data <- filter(d.state, site == si)
  # litSemantics <- filter(litSemantics.results, site == si)
  
  # litSemantics.toPass <- as.list(litSemantics %>%
  # select(state, utterance, MAP) %>%
   # litSemantics.toPass <- as.list(litSemantics.results %>%
   #                                select(state, utterance, MAP) %>%
   #                                 spread(utterance, MAP))
   # litSemantics.toPass <- as.list(litSemantics.results) %>%
   #                                  select(state, utterance, theta) %>%
   #                                  spread(utterance, theta))
     litSemantics.toPass <- litSemantics.results

  dataToWebPPL <- list(literalSemantics = litSemantics.toPass,
                       # data = site.data)
                       data = d.utterance)
  
  # toJSON(as.list(litSemantics.toPass), pretty = T)
  
  # rsa.output <- webppl(pRSA,
  #                    data = dataToWebPPL,
  #                    data_var = "dataFromR")
  # 
  bda.utterance.results <- webppl(fullModel,
                              data = dataToWebPPL,
                              data_var = "dataFromR",
                              inference_opts = list(method = "MCMC", 
                                                    samples = 10,
                                                    burn = 5,
                                                    verbose = TRUE),
                              model_var = "dataAnalysis",
                              output_format = "samples",
                              chains = 1,
                              cores = 1)
  #dataToWebPPL
# write.csv(bda.utterance.results,paste(local.path,
#                       "model/results/bda-politeRSA-speaker2GivenStateGoal_mixtureWeight-10000burn5000.csv",sep=""), # CHANGE FILE NAME AS NEEDED
#           row.names=FALSE)

```

# exp vs. BDA analysis

```{r callOnData}
# bda.utterance.results <- read.csv(paste(local.path,
#                         "model/results/bda-politeRSA-speaker1GivenStateGoal-80000burn40000.csv",
#                         sep = ""))
# bda.utterance.results <- fread(paste(local.path,
#                         "model/results/bda-politeRSA-speaker1GivenStateGoal_mixtureWeight-10000burn5000.csv",
#                         sep = ""))
# 
# summary(bda.utterance.results$speakerOptimality_NA_NA_NA)
# summary(bda.utterance.results$alpha_NA_NA_NA)
# 
bda.utterance.tidy <- bda.utterance.results %>%
    select(contains("posteriorPredictive"), -contains("negation")) %>%
    gather(key, val) %>%
    # mutate(key = gsub("value.", "", key)) %>% # for mht
    separate(key, into = c("param", "goal", "state", "positivity", "utterance")) %>%
  mutate(utterance = factor(utterance, levels = c("terrible", "bad", "okay", "good", "amazing")),
         positivity = factor(positivity, labels = c("neg", "no_neg")),
         positivity = factor(positivity, levels = c("no_neg", "neg"))) %>%
    group_by(goal, state, positivity, utterance) %>%
  filter(!is.na(val)) %>%
  # summarise(val = mean(val))
  summarize(MAP = estimate_mode(val),
            ci_lower = hdi_upper(val),
            ci_upper = hdi_lower(val))

  # multi_boot_standard(column = "val") %>%
  # mutate(val = mean)

# write.csv(bda.state.tidy,paste(local.path,
#                       "model/results/bda-politeRSA-speaker1GivenStateGoal-mixtureWeight-postLongForm.csv",sep=""), # CHANGE FILE NAME AS NEEDED
#           row.names=FALSE)

#bda.utterance.tidy <- fread(paste(local.path,
#                        "model/results/bda-politeRSA-speaker1GivenStateGoal-mixtureWeight-postLongForm.csv",
#                        sep = ""))
```

```{r model_predictions_eachUtt}
bda.utterance.tidy2 <- bda.utterance.tidy %>%
  filter(!is.na(val)) %>%
  group_by(goal, state, positivity, utterance) %>%
  distinct(val, .keep_all = TRUE)

bda.utterance.tidy3 <- bda.utterance.tidy %>%     
  group_by(goal, state, positivity, utterance) %>%
  # summarise(val = mean(val)) %>%
  filter(!is.na(val)) %>%
  summarize(
    MAP = estimate_mode(val),
            ci_lower = hdi_lower(val),
            ci_upper = hdi_upper(val)) %>%
  ungroup() %>%
  mutate(goal = factor(goal, levels = c("informative", "social", "both"))) %>%
  mutate(goal = factor(goal, labels = c("informative", "social", "Model pred for goal:both")))
  
bda.utterance.tidy3_org <- bda.utterance.tidy3 %>%
  mutate(utterance = factor(utterance, levels = c("terrible", "bad", "okay", "good", "amazing")),
         state = factor(state, labels = c("1 heart", "2 hearts", "3 hearts", "4 hearts", "5 hearts")),
         positivity = factor(positivity, levels = c("no_neg", "neg")),
         positivity = factor(positivity, labels = c("no negation", "negation")))

ggplot(data=bda.utterance.tidy, aes(x=positivity, y=MAP, fill=utterance)) +
  geom_bar(stat="identity", position=position_dodge()) +
  facet_grid(goal~state) +
  xlab("no neg (it was ~) vs neg (it wasn't ~) ") +
  ylab("proportion chosen") +
  # ggtitle("What would the speaker say given their goals?") +
  geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper),position="dodge") +
  geom_hline(yintercept=.1, lty=2) +
  theme_bw()+
  ylim(0,1)
```

```{r model_predictions_negNoneg}
bda.utterance.tidy4 <- bda.utterance.results %>%
    select(contains("negation")) %>%
    gather(key, val) %>%
    # mutate(key = gsub("value.", "", key)) %>% # for mht
    separate(key, into = c("param", "goal", "state", "positivity")) %>%
  mutate(val_noNeg = 1-val) %>%
  gather(posneg, val, val:val_noNeg) %>%
  select(-positivity) %>%
  mutate(positivity = factor(posneg, labels = c("negation", "no_negation"))) %>%
  select(-posneg) %>%
  group_by(goal, state, positivity) %>%
  # summarise(val = mean(val))
  summarize(MAP = estimate_mode(val),
            ci_lower = hdi_upper(val),
            ci_upper = hdi_lower(val))

ggplot(data=bda.utterance.tidy4, aes(x=state, y=MAP, col=positivity, group=positivity)) +
  # geom_bar(stat="identity", position=position_dodge()) +
  geom_line(stat="identity", position=position_dodge()) +
  facet_grid(goal~.) +
  xlab("true state") +
  ylab("proportion chosen") +
  geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper), position=position_dodge(width=.05)) +
  # ggtitle("negation (indirect remark) vs. no negation (white lie)")
  scale_colour_discrete(guide = guide_legend(title = "utterance type"))
```

```{r expModelTogether}
ms_data <- ms.all
levels(ms_data$goal)
levels(ms_data$goal) <- c("both", "informative", "social")
ms_data <- ms_data %>%
    mutate(MAP = as.numeric(as.character(mean)),
    ci_upper = as.numeric(as.character(ci_upper)),
    ci_lower = as.numeric(as.character(ci_lower))) %>%
  select(-mean) %>%
  mutate(goal = as.factor(goal),
         true_state = as.factor(true_state),
         positivity = as.factor(positivity),
         utterance = as.factor(utterance))

levels(ms_data$true_state) <- c(1:5)
levels(ms_data$positivity) <- c("neg", "no_neg")


ms_model <- bda.state.tidy3 %>%
  mutate(true_state = state) %>%
  ungroup() %>%
  select(-state) %>%
  mutate(
    model_MAP = as.numeric(as.character(MAP)),
    model_ci_upper = as.numeric(as.character(ci_upper)),
    model_ci_lower = as.numeric(as.character(ci_lower))) %>%
  select(-MAP, -ci_upper, -ci_lower) %>%
  mutate(goal = as.factor(goal),
         true_state = as.factor(true_state),
         positivity = as.factor(positivity),
         utterance = as.factor(utterance))
ms_all <- left_join(ms_data, ms_model) %>%
  mutate(goal =factor(goal, levels=c("informative", "social", "both")))
```

```{r expModelTogether_plot}
ggplot(ms_all, aes(x = model_MAP, y = MAP, col=goal)) +
  geom_point() +
  geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper)) +
  geom_errorbarh(aes(xmin=model_ci_lower,xmax=model_ci_upper)) +
  geom_abline(intercept = 0, slope = 1, linetype = 3) +
  xlab("Model posterior predictive") +
  ylab("Human proportion responses") +
  ylim(0,0.95) +
  xlim(0,0.95) +
  coord_fixed()

# cor.test(ms_all$MAP, ms_all$model_MAP) # 0.8744156 ^2 = 0.7646

```


```{r inferredGoalWeight}
bda.state.tidy2 <- bda.utterance.results %>% 
    select(contains("phi")) %>%
    # select(contains("weight")) %>%
    gather(key, val) %>% 
    # mutate(key = gsub("value.", "", key)) %>% # for mht
    separate(key, into = c("param", "goal", "state", "utterance")) %>%
  mutate(epistemic = val,
         social = 1-val) %>%
  select(-val) %>%
  gather(weight, val, epistemic:social) %>%
  mutate(weight = factor(weight, labels = c("epistemic", "social")),
         goal = factor(goal, levels = c("informative", "social", "both")))
  # ggplot(., aes(x = val))+
  # geom_histogram(binwidth=0.01)+
  # facet_grid(goal~param)

# group_by(goal, param) %>%
#   summarize(MAP = estimate_mode(val),
#             cred_upper = hdi_upper(val),
#             cred_lower = hdi_lower(val))

# bda.state.tidy2 <- bda.utterance.results %>% 
#     select(contains("weight")) %>%
#     gather(key, val) %>% 
#     # mutate(key = gsub("value.", "", key)) %>% # for mht
#     separate(key, into = c("param", "goal", "state", "utterance")) %>%
#   mutate(weight = factor(param, labels = c("epistemic", "social")),
#          goal = factor(goal, levels = c("informative", "social", "both"))) %>%
#   ggplot(., aes(x=val, fill = weight))+
#   geom_density(alpha=0.5, adjust = 1.5, color ='black', size = 1.1)+
#     facet_grid(goal~., scales='free')+
#   theme_bw()+
#   ylab("posterior density")+
#   xlab("Inferred speaker goal weight")

  ggplot(data=bda.state.tidy2, aes(x=val, fill = weight))+
  geom_density(alpha=0.5, adjust = 2.5, color ='black', size = 0.5)+
    facet_grid(goal~., scales='free')+
  theme_bw()+
  ylab("posterior density")+
  xlab("Inferred speaker goal weight")
```
      
      
```{r alphaOptimalityCost}

bda.utterance.results %>%
  # select(value.speakerOptimality_NA_NA_NA, value.alpha_NA_NA_NA, value.cost_NA_NA_NA) %>%
  select(speakerOptimality_NA_NA_NA, alpha_NA_NA_NA, cost_NA_NA_NA) %>%
    gather(key, val) %>%
    # mutate(key = gsub("value.", "", key)) %>% # for mht
    separate(key, into = c("param", "goal", "state", "utterance")) %>%
  ggplot(., aes(x = val))+
  geom_histogram()+
  facet_wrap(~param)

bda.utterance.results %>% 
  # select(value.speakerOptimality_NA_NA_NA, value.alpha_NA_NA_NA, value.cost_NA_NA_NA) %>%
  select(speakerOptimality_NA_NA_NA, alpha_NA_NA_NA, cost_NA_NA_NA) %>%
    gather(key, val) %>% 
    # mutate(key = gsub("value.", "", key)) %>% # for mht
    separate(key, into = c("param", "goal", "state", "utterance")) %>%
  group_by(param) %>%
  summarize(
    MAP = estimate_mode(val),
            ci_lower = hdi_lower(val),
            ci_upper = hdi_upper(val))
  
```
