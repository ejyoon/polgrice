---
title: "\"I won't lie, it wasn't amazing\": Modeling polite indirect speech"
bibliography: politeness.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 

 \author{{\large \bf Erica J. Yoon}, {\large \bf Michael Henry Tessler}, {\large \bf Noah D. Goodman} \and {\large \bf Michael C. Frank}  \\
         \{ejyoon, mtessler, ngoodman, mcfrank\} @stanford.edu \\ 
         Department of Psychology, Stanford University}

abstract: 
    "Why do people speak politely? Previous work has suggested that people expect others to speak based on their desires to be transfer accurate information (epistemic goal) and to make the listener feel good (social goal), sometimes causing them to produce white lies [@yoon2016]. In the current work, we expand on this theory to consider another prominent case of polite speech: indirect remarks. We show that people expect a speaker to produce more of vague indirect remarks (e.g. \"It wasn't amazing\") when there is greater risk of face threat and the speaker wants to be considerate and informative at the same time. We also compare goal attributions to speakers who produce direct versus indirect remarks, and find that, when face threat risks are high, people attribute more extreme tradeoff decisions between the epistemic vs. social goal for direct remarks, but report greater balance between the two goals for indirect remarks. FIXME: These results align with our model predictions, demonstrating great generalizability of our model.
    "

keywords:
    "Politeness; computational modeling; communicative goals; pragmatics"
    
output: cogsci2016::cogsci_paper
---


```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
```

# Introduction

Language users hear and produce *polite speech* on a daily basis. But being polite conflicts with one important goal of cooperative communication: exchanging information efficiently and accurately [@Grice1975]. To be polite, people produce indirect requests that are much longer than simple imperatives ("It would be great if you could close that window" as opposed to "Close that window."), and tell white lies to make others feel good ("Your new dress is gorgeous!") Thus, speakers convey information inefficiently and risk losing accurate information (indirect speech) or even intentionally convey wrong information (lies). If information transfer was the only currency in communication, a cooperative speaker would find polite utterances undesirable because they are potentially misleading. 

However, people are polite. Adults and even young children spontaneously produce requests in polite forms [@clark1980; @axia1985], and speakers use politeness strategies even while arguing, preventing unnecessary offense to their interactants [@holtgraves1997]. Do these facts about politeness imply that people are not cooperative communicators in the Gricean sense? 

One prominent theory by @Brown1987 recast the notion of a *cooperative speaker* as one who has both an epistemic goal to improve the listener's knowledge state as well as a social goal to minimize any potential damage to the hearer's (and the speaker's own) self-image, which they called *face*. In their analysis, if the speaker's intended meaning contains no threat to the speaker or listener's face, then the speaker will choose to convey the meaning in an efficient manner, putting it *on the record*. As the degree of face-threat becomes more severe, however, a speaker will choose to be polite by producing more indirect utterances. 

Inspired by this set of ideas, in our previous work, we argued that language users think about polite speech as reflecting a tradeoff between information transfer and face-saving [@yoon2016]. When a speaker tries to save face, she hides or risks losing information in her intended message by making her utterance false or indirect to some degree. On the other hand, when a speaker prioritizes truthfulness and informativity, she may risk losing the listener's (or the speaker's own) face. We developed a novel computational model that captures the idea that cooperative speakers attempt to balance between the two goals: information transfer and face-saving. This model built on a recent formal framework for modeling pragmatic language understanding, the "rational speech act" (RSA)  model [@Frank2012; @Goodman2013]. To test our model empirically, we examined a case study of polite speech: white lies. We looked at people’s inferences about a speaker who observed someone’s performance (e.g. presentation) and either produced a white lie ("It was amazing") or bluntly spoke the truth ("It was terrible") to varying degrees of deviations from the true state (true rating deserved by the performance) and found that our model captured key patterns in the inference data.

How generalizable is our model? Our previous work only focused on white lies vs. blunt truths, which means that in the face of a conflict between the two goals, the speaker had to choose one goal over the other. For example, if Bob gave a terrible performance, Alice could decide to prioritize face-saving but forgo information transfer and say “it was amazing,” or she could value information transfer more than face-saving and say “it was terrible.” But what if the speaker wanted a greater balance between the two goals? In this work, we add another possible case study of polite speech: *indirect speech*. In the context of our model, we define indirect speech as vague assertion with the use of negation (e.g. “It wasn’t amazing”). 

What goals may lead a speaker to produce indirect speech? If Alice observes Bob’s terrible presentation and decides to say about it, "it wasn't amazing", this may reflect a greater balance between the two goals: informationally, "not amazing" does not preclude the possibility that the presentation was bad, so the utterance is now not a downright lie; and socially, Alice still tries to save Bob’s face by not saying the explicitly negative thing, even though Bob will probably be able to infer the implied meaning. On the other hand, if the presentation was actually good, or even decent, Alice will prefer to produce a directly positive remark ("It was good"). Thus we predict that a speaker who wants to balance between epistemic and social goals would produce indirect speech relatively more, especially when the true state is bad. We also predict that a listener who hears indirect speech would recognize speaker’s desire for greater balance between the two goals. Importantly we argue that it is the interaction between presence of face threat (due to addressee's poor performance) and speaker's consideration of both epistemic and social goals that is predicted to lead to greater degree of indirect speech production. In what follows, we confirm our hypotheses on our formal model and two empirical tests. 

# Computational Model

In the current work, we build on our previous formal model that assumes speaker to choose utterances approximately optimally given a utility function, a standard assumption made in family of RSA models [@yoon2016; @Goodman2013]. We proposed that there are two utilities considered by the speaker. First, *epistemic utility* ($U_{epistemic}$) refers to the amount of information a *literal listener* would still not know about world state $s$ after hearing a speaker's utterance $w$ (*surprisal* that the speaker would want to minimize) minus a non-negative cost $C(w)$; Second, *social utility* ($U_{social}$) is the expected utility of the state the listener would infer given the utterance $w$, which is related to the intrinsic value of the state from the listener's viewpoint, where a value function ($V$)  maps states to subjective utility values and thus captures the affective consequences for the listener of being in state $s$. Thus we defined the overall speaker utility ($U$) to be a weighted combination of epistemic and social utilities.

$$U_{epistemic}(w; s) = \ln(P_{L_0}(s \mid w))- C(w)$$

$$U_{social}(w; s) = \mathbb{E}_{P_{L_0}(s \mid w)}[V(s)]$$

$$U(w;s;  \hat{\beta}) = \beta_{epistemic}\cdot U_{epistemic} + \beta_{social} \cdot U_{social}$$

We define the literal listener ($L_0$) is a simple Bayesian agent that takes the utterance to be true. The pragmatic speaker ($S_1$) chooses utterances $w$ softmax-optimally given the state $s$ and his goal weights $\hat{\beta}$. The pragmatic listener ($L_1$) infers the world state based on this speaker model. We will assume the listener does not know exactly how the speaker weights his competing goals, however. We assume the pragmatic listener jointly infers the state $s$ and the utility weights of the speaker, $\beta_{epistemic}$ and $\beta_{social}$ [@GoodmanLassiter2015; @Kao2014]. The meta-pragmatic speaker then chooses an utterance based on the pragmatic listener model, thinking about the state as well as goal weights that the pragmatic listener will infer.

$$P_{L_0}(s \mid w)\propto {w}(s) \cdot P(s)$$ 

$$P_{S_1}(w \mid s, \hat{\beta}) \propto \mathrm{exp}(\lambda \cdot \mathbb{E}[U(w; s;  \hat{\beta})])$$

$$P_{L_1}(s,  \hat{\beta} \mid w)\propto P_{S_1}(w \mid s,  \hat{\beta})\cdot P(s) \cdot P( \hat{\beta})$$
$$P_{S_2}(w \mid s, \hat{\beta})\propto \mathrm{exp}(\lambda \cdot P_{L_1}(s,  \hat{\beta} \mid w) \cdot P(w))$$

Within our experimental domain, we assume there are five possible states of the world corresponding to the value placed on a particular referent (e.g. rating deserved by the presentation the speaker is commenting on): $S = \{s_{1}, ...,  s_{5}\}$. We further assume a uniform prior distribution over possible states of the world. The states have subjective numerical values $V(s_{i}) = \alpha \cdot i$, where $\alpha$ is a scaling parameter (later inferred from data).

The current work builds on our previous formal model by adding simple but key components to predict indirect remark production and comprehension. First, there had previously been five possible utterances: {It was *terrible*, *bad*, *okay*, *good*, and *amazing*}, all direct assertions of specific states (e.g. "It was amazing" would be true for the state of 5 but untrue for the states of 1 or 2). To probe people's inferences about indirect remarks, we added five utterances to the set: {It *wasn't* terrible, bad, okay, good, and amazing}. These utterances indirectly address the referent by negating certain state. Second, the cost of longer utterances (it is more costly to say "It wasn't terrible" than "It was amazing" due to inclusion of negation; @GoodmanLassiter2015) was accounted for by holding constant the costs of direct remarks with no negation (e.g. cost = 1) and inferring the posterior credible values of the costs of indirect remarks (w ~ Uniform(0,20)) from data in each experiment. We implemented this model using the probabilisitic programming language WebPPL [@dippl] and a complete implementation can be found at \url{FIXME}.

We first measure the literal semantics, then use these for model predictions on speaker production of indirect speech vs. direct speech (with no negation). We compare these model predictions against empirical data on people's expectations for speaker production of utterances $u$ given a state and a speaker's goal (Experiment 1), and confirm that our model predictions capture the key patterns in the data. We then investigate listeners' inferences about speakers' goals given an utterance and a state in Experiment 2, and find that listener inferences are consistent with our hypothesis that indirect speech reflects a greater balance between epistemic and social goals.

# Semantic measurement

We first probed judgments of literal meanings of the target words assumed by our model and used in all our experiments. These judgments will be used as the expected literal meaning priors in our model.

```{r expt1_screen, fig.env = "figure", fig.pos = "t", fig.align='center', fig.width=2, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.cap = "Example of a trial in semantic measurement task."}
#img <- png::readPNG("figs/expt1_screen.png")
#grid::grid.raster(img)
```

```{r expt1_results, fig.env = "figure*", fig.pos = "t", fig.width=7, fig.height=4, fig.align = "center", fig.cap = "Semantic measurement results. Proportion of acceptances of utterance types (shown in different colors) combined with target words (shown in different facets) given the true state represented on a scale of hearts. Error bars represent 95\\% confidence intervals."}
# "Semantic measurement results. Proportion of acceptances of utterance types (shown in different colors) combined with target words (shown in different facets) given the true state represented on a scale of hearts. Error bars represent 95% confidence intervals."}
img <- png::readPNG("figs/expt1_results.png")
grid::grid.raster(img)
```

## Method 

### Participants 

25 participants with IP addresses in the United States were recruited on Amazon's Mechanical Turk.

### Stimuli and Design

We used 13 different context items that were previously used in @yoon2016, in which someone evaluated a performance of some kind (e.g. presentation). For example, in one of the contexts, Bob saw a presentation, and Bob's feelings toward Ann's cake (*true state*) were shown on a scale out of five hearts (e.g. two out of five hearts filled in red color). The question of interest was "Do you think Bob thought the presentation was / wasn't X?" where X could be one of five possible words: *terrible*, *bad*, *okay*, *good*, and *amazing*, giving rise to ten different possible utterances (with negation or no negation). Each participant read 50 scenarios, depicting every possible combination of 5 true states and 10 utterances. The order of context items was randomized, and there were a maximum of four repeats of each context item per participant.

### Procedure

Participants read scenarios and indicated their answer to each question by answering "No" or "Yes." The experiment can be viewed at: \url{https://langcog.stanford.edu/expts/EJY/polgrice/negimp_prior_v1/negimp_prior.html}.

### Results 

For this and all subsequent experiments, we analyze the data by collapsing across context items. Meanings of the words as judged by participants were as one would expect (see Figure 1). For utterances without negation (e.g. "It was terrible"), proportion of acceptances for a word given the true state peaked where the degree of positivity, neutrality and negativity of the state matched that of the word, replicating literal semantics reported in @yoon2016. For utterances with negation (e.g. "It wasn't terrible"), proportion of acceptances were inverses of acceptances for non-negated words. The fraction of participants that endorsed utterance $w$ for state $s$ will be used as the literal meaning priors, and we infer posterior credible values of the literal meanings (${w}(s)$) from data in each experiment.

# Model predictions

## Model parameters

To model what speakers would say given true states and their goals (e.g. wanting to make the listener feel good), we assume a particular set of speaker's goal-weights {$\beta_{epistemic}$, $\beta_{social}$} to represent three goal conditions that we are interested in: *informative* (high weight of FIXME on epistemic utility, low weight of FIXME on social utility); *social* (high social weight of FIXME, low epistemic weight of FIXME); and *both goals* (moderately high weight of FIXME on both utilities). 

There are four additional parameters of the model, and for the purposes of generating model predictions a priori, we will assign reasonable parameters based on pilot runs of the model-data fit: the pragmatic speaker optimality parameter ($\lambda_{S_1}$ assigned to FIXME); the meta-pragmatic speaker optimality parameter ($\lambda_{S_2}$ to FIXME); the value scale parameter ($\alpha$ to FIXME) in the utility function; and the cost parameter ($C(u)$ to FIXME). 

### Results

The predictions for the speaker's utterance were consistent with our hypothesis, namely that indirect speech was relatively more preferred given bad true states (e.g. 1 heart) and speaker's consideration of both epistemic and social goals (Figure 2). Whereas positive direct remarks were highly likely for good true states (4-5 hearts) across all three goal conditions, only for the both goal condition did the model infer higher likelihood of indirect than direct remarks for the worst true state (1 heart). The model also predicted the tendency of an "informative" speaker to prioritize the most truthful direct remark (e.g. "It was terrible" given 1 heart) and tendency of a "social" speaker to favor positively-biased direct remarks (e.g. "It was okay" for 2 hearts). Overall, the model predictions supported our hypothesis that face threat in the true state and both epistemic and social utilities contribute to greater production of indirect speech. Next, we confirm these model predictions in an experiment. 

```{r model_pred_negNoneg, fig.env = "figure*", fig.pos = "t", fig.width=6, fig.height=3, fig.align = "center", fig.cap = "Model predictions (top) and experimental data (bottom) collapsing across different words to show average proportion of utterance type (shown in different colors) given by true states (x-axis) and goals (columns)."}
img <- png::readPNG("figs/expt1_modelPred.png")
grid::grid.raster(img)
```

# Experiment 1: Speaker production

To confirm our model predictions, in Experiment 1, we examined people's predictions for the most likely utterance produced by the speaker ($u$), given a description of the true state of the world (e.g. the speaker felt that a poem deserved 2 out of 5 hearts) and the speaker's goals (e.g. the speaker wanted to make the listener feel good). Critically, the contexts indicated face threats toward the listener, as the speaker's utterance was an evaluation of the listener's performance. We hypothesized that when there is no tradeoff between informativity and face-threat avoidance (i.e. when the addressee's performance is great), speakers should use truthful and face-saving direct remarks ("[Your talk] was amazing") regardless of their described goals. However, when there is a conflict between the epistemic and social goals (i.e. when the addressee's performance is poor), a speaker who tries to compromise between both goals would use vague indirect remarks more often than direct face-threatening reamrks (blunt truth; preferred by an informative speaker) or direct face-saving remarks (i.e. white lies; preferred by face-saving speaker). On the other hand, Our hypothesis and method was pre-registered prior to data collection on the Open Science Framework (\url{http://osf.io/b73dm}). 

## Method

### Participants

202 participants with IP addresses in the United States were recruited on Amazon's Mechanical Turk.

### Stimuli and Design

We designed scenarios in which a person (e.g. Ann) gave some performance and asked for another person (e.g. Bob)'s opinion on the performance. The same context items and true states as Experiment 1 were used. Additionally, we provided information on the speaker Bob's goal (*to make Ann feel good*, or *to give as accurate and informative feedback as possible*, or both) and the true state, or how Bob actually felt Ann's performance (e.g. 2 out of 5 hearts), Then we asked participants to predict what Bob would say, out of 10 possible utterances ("It was terrible", "It was bad" ... "It wasn't good", "It wasn't amazing"). Each participant read 15 scenarios, depicting every possible combination of 3 goals and 5 states. The order of context items was randomized, and there were a maximum of two repeats of each context item per participant.

### Procedure

Participants read each scenario followed by a question that read, "If Bob wanted *to make Ann feel good* (or *to give accurate and informative feedback*, or *BOTH make Sarah feel good AND give accurate and informative feedback*), what would Bob be most likely to say?" Participants indicated their answer by choosing one of the options on the two dropdown menus, side-by-side, one for choosing between *was* vs. *wasn't* and the other for choosing among *terrible*, *bad*, *okay*, *good*, and *amazing* (see Figure 3).
The experiment can be viewed at: \url{https://langcog.stanford.edu/expts/EJY/polgrice/speaker_production_dropdown_v2/speaker.html}.


## Behavioral results

```{r expt2_screen, fig.env = "figure", fig.pos = "t", fig.width=3.5, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Example of a trial in Experiment 1."}
img <- png::readPNG("figs/expt2_screen.png")
grid::grid.raster(img)
```

Our hypotheses for utterance production by speakers with different goals were borne out: People's predictions for speaker's use of indirect vs. direct remarks given varied depending on speaker's goals, and these differences wre especially pronounced for worse true states (Figure 3, bottom). 
For good states (4 and 5 hearts), positive direct remarks were judged to be the most likely utterances across all three goal conditions. For less-than-perfect, but still decent states, there was a greater degree of expectation of white lies (e.g. "It was amazing" for 4 hearts) given social goal (Figure 4, right). 
For bad states (1 and 2 hearts), as we predicted, there were more instances of expected indirect remarks overall across all goal conditions given bad states. Critically, speakers with both goals to be informative and socially considerate produced more indirect than direct remarks, unlike the other two goal conditions. Thus, these results indicated that a speaker who considers both informative and social goals, and thus is in want of a compromise between the two, is expected to produce relatively more indirect remarks.

```{r expt2_results, fig.env = "figure*", fig.pos = "t", fig.width=8, fig.height=3, fig.align = "center", fig.cap = "Experimental results (right) and model predictions (left; first two columns) for Experiment 1. Proportion of utterances chosen (utterance type -- direct vs. indirect -- on x-axis and words shown in different colors) given the true state (columns) and speaker goals (rows). Error bars represent 95\\% confidence intervals for the data and 95\\% highest density intervals for the model."}
img <- png::readPNG("figs/expt2_modelExp.png")
grid::grid.raster(img)
```

```{r expt2_model, fig.env = "figure", fig.pos = "b", fig.width=3, fig.height=3, fig.align = "center", fig.cap = "Full distribution of human responses vs. model predictions. Error bars represent 95\\% confidence intervals for the data and 95\\% highest density intervals for the model."}
img <- png::readPNG("figs/expt1_modelExpCor.png")
grid::grid.raster(img)
```

## Model predictions

### Model fitting

In this experiment, participants were told true states and what speakers' intentions were (e.g. Bob wanted to make Alice feel good). We assume that the intention descriptions conveyed to the participants a particular set of goal-weights {$\beta_{epistemic}$, $\beta_{social}$} that the speaker was using. We put uninformative priors on these weights ($\beta$ ~ Uniform(0,1)) and infer their credible values separately for each goal condition ("wanted to X") using Bayesian data analytic techniques [@LW2014].

As for the four additional parameters of the model, we put uninformative priors on these ($\lambda_{S_1}$ ~ Uniform(0,20); $\lambda_{S_2}$ ~ Uniform(0,5); $\alpha$ ~ Uniform(0,5); $C(w)$ ~ Uniform(1,10)) and infer their posterior credible values from the data. FIXME We ran 2 MCMC chains for 80,000 iterations, discarding the first 40,000 for burnin. The Maximum A-Posteriori (MAP) estimate and 95% Highest Probability Density Interval (HDI) for $\lambda$ is 2.48 [2.30, 3.11]; for $\alpha$ is 1.77 [1.34, 2.54]. To generate utterance predictions, given our cognitive model and the inferred parameters, we evaluated the posterior predictive distribution, marginalizing out all parameters. 

### Results

The inferred weights for each goal condition were largely as expected: For the "wanted to give informative feedback" (*informative*) condition, the model puts a high weight on epistemic utility (FIXME) but a low weight on social utility (FIXME). For the "wanted to make [the listener] feel good" (*social*) condition, the model infers the speaker was using a moderate weight on social utility (FIXME) and a low weight on epistemic utility (FIXME). For the "wanted BOTH to make [the listener] feel good and give informative feedback" (*both*) condition, the model assigned appreciable weights on both epistemic and social utilities (FIXME and FIXME, respectively). The predictions of the expectations of the speaker model for the speaker's utterance were consistent with the experimental findings (predictions for true states of 1 and 2 hearts shown in Figure 4, left). Overall, the expected values of the model explain a substantial amount of the variance in the average data $r^2$(15) = 0.752 (Figure 5), and thus our cognitive model captured key aspects of our empirical findings for indirect vs. direct remark production. 

# Experiment 2: Goal inference

Experiment 2 probed listeners' inferences of the speaker's goals, given an utterance (e.g. "It wasn't amazing") and a true state (e.g. 2 out of 5 hearts). 

## Method

### Participants

60 participants with IP addresses in the United States were recruited on Amazon's Mechanical Turk.

### Stimuli and Design

We presented the same context items and true states (i.e. how Bob actually felt towards Ann's performance) as Experiment 2, but instead of goals we provided Bob's utterances ("It wasn't amazing"). Then we asked participants to infer the likelihood of Bob's goals to *to make Ann feel good*, or *to give accurate and informative feedback*. Each participant was randomly assigned to one of two conditions to read 25 scenarios, depicting half (counterbalanced) of all possible combinations of 5 true states and 10 utterances. The order of context items was randomized, and there were a maximum of two repeats of each context item per participant.

### Procedure

Participants read each scenario followed by a question that read, "Based on what Bob said, how likely do you think that Bob's goal was to: *to make Ann feel good*; *to give accurate and informative feedback*" with the two goals placed in a random order next to two slider bars, on which the participant could indicate each goal's likelihood. 
The experiment can be viewed at: \url{https://langcog.stanford.edu/expts/EJY/polgrice/L2_G_Neg/polgrice_L2_G.html}.

## Behavioral results

```{r expt3_results, fig.env = "figure*", fig.pos = "b", fig.width=8, fig.height=2, fig.align = "center", fig.cap = "Results from Experiment 2. Attribution of speaker's goals: to give accurate and informative feedback (informative) and to make [the listener] feel good (social). Error bars represent 95\\% CIs."}
img <- png::readPNG("figs/expt2_results_goal.png")
grid::grid.raster(img)
```

Participants rated speaker's goals differentially depending on the true state and utterance (see Figure 6).
Results for direct remarks with no negation replicated our previous findings: 
Goal to be informative was rated highest when the true state was most consistent with the literal meanings. 
As direct remarks became more positive, participants increased in their attribution of speaker's goal to make the listener feel good. 

Comparison of direct versus indirect remarks revealed an interesting asymmetry. 
For positive states (4 and 5 hearts), both informative and social goal attributions increased with more positive valence of the direct remarks, whereas both goal attributions mostly stayed low below chance level across all indirect remarks.
For negative states (1 and 2 hearts), interesting similarities and differences between the two types of utterances were observed. Similarly between the two, there was a crossover in goal attribution, caused by tradeoff between utterance-meaning match (informative goal) and face-saving (social goal). 
This tradeoff however is much more exaggerated in direct than indirect remarks: saying "It was amazing" given a state of 1 heart blatantly prioritizes social goal and forgos informative goal. 
On the other hand, indirect remarks present a more balanced decision: saying "It wasn't amazing" moderately satisfies both goals. Again, this finding confirms that a speaker who seeks a compromise between the goals to be informative and to save face produces more indirect remarks, and this desire then to be recognized by the listener. 

# Discussion

In this work, we showed that our formal model with two speaker utilities (epistemic and social) can be used to not only explain white lie understanding but also indirect remark production and comprehension. Our model predicted that speakers produce more indirect remarks given poorer performance of the addressee (thus involve greater face threat) and speaker's goal to both be informative and to save face, and experimental data confirmed these predictions (Experiment 1). Consistent with this, participants attributed a greater balance of the two goals to a speaker who produced indirect remarks given bad true states (Experiment 2). 

An important contribution of this work is in showing the generalizability of our formal model to different kinds of polite speech (white lies and indirect remarks). Can the model be extended to other polite speech phenomena? One significant factor to take into account will be speaker's self-presentation: Not only will a speaker want to save the listener's face, but she also will want to save her own face. Thus, examining how our model's utilities can be extended to speaker's desire to save her own face by appearing polite, genuine, or modest will be an important next step. Using the model to explore other kinds of polite speech such as indirect requests ("Would you mind closing the window?") [@clark1980] and  manifestations of polite speech in different cultures [e.g. @holtgraves1990] will also be important directions for future research.

In sum, our formal model and experimental work present a key contribution to polite speech understanding. With a minimal extension to our existing model, we were able to capture subtle patterns in people's inferences for indirect speech. Through empirical findings compared against our model predictions on indirect speech, we showed that neither epistemic nor social motives alone motivate indirect speech; instead, the need for indirect speech results from the conflict between these two. These findings provide strong support for our utility-theoretic framing of politeness, and promises next concrete steps in pragmatic understanding.

# Acknowledgements

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
