---
title: "\"I won't lie, it wasn't amazing\": Modeling polite indirect speech"
bibliography: politeness.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 

 \author{{\large \bf Erica J. Yoon}, {\large \bf Michael Henry Tessler}, {\large \bf Noah D. Goodman} \and {\large \bf Michael C. Frank}  \\
         \{ejyoon, mtessler, ngoodman, mcfrank\} @stanford.edu \\ 
         Department of Psychology, Stanford University}

abstract: 
    "Why are we polite when we talk to one another? One hypothesis is that people expect others to choose what to say based on their goals both to transfer information efficiently (an epistemic goal) and to make the listener feel good (a social goal). In our previous work, we found that when these two goals conflict, they sometimes produce white lies. In the current work, we expand on this theory to consider another prominent case of polite speech: indirect remarks using negation (e.g., \"It wasn't amazing\"). With minimal extensions from our previous framework, our formal model suggests that a pragmatic speaker will produce more indirect remarks when the speaker wants to be considerate and informative at the same time. These predictions were borne out in an experiment on language production. These findings suggest that the conflict between social and epistemic goals can account for a broad range of politeness phenomena."

keywords:
    "Politeness; computational modeling; communicative goals; pragmatics"
    
output: cogsci2016::cogsci_paper
---

\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}
\definecolor{Orange}{RGB}{255,153,0}

\newcommand{\ejy}[1]{\textcolor{Red}{[ejy: #1]}}  
\newcommand{\ndg}[1]{\textcolor{Green}{[ndg: #1]}}  
\newcommand{\mht}[1]{\textcolor{Blue}{[mht: #1]}}  
\newcommand{\mcf}[1]{\textcolor{Orange}{[mcf: #1]}}

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "t!", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
```

```{r setup, include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(binom)
library(rwebppl)
library(jsonlite)
library(readr)
library(coda)
library(magrittr)
library(ggthemes)
library(forcats)
library(langcog)
# set path to working dir
# local.path <- "~/Documents/research/polgrice/"
#local.path <- "~/Documents/Research/polgrice_GIT/"
#source(paste(local.path, "experiment/data_analysis/markdown/polgrice_S.R", sep=""))

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
# HPDhi<- function(s){
hdi_upper <- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
# HPDlo<- function(s){
hdi_lower <- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
options("scipen"=10)   

```

# Introduction

Language users hear and produce *polite speech* on a daily basis. 
Adults and even young children spontaneously produce requests in polite forms [@clark1980; @axia1985], and speakers use politeness strategies even while arguing, preventing unnecessary offense to their interactants [@holtgraves1997]. 
But being polite conflicts with one important goal of cooperative communication: exchanging information efficiently and accurately [@Grice1975]. 
People tell white lies ("Your new dress is gorgeous!") and produce indirect speech that is longer and more nuanced than the simplest form of their intended message ("I don’t think that dress looks phenomenal on you" as opposed to “That dress looks terrible”) to make others feel good about themselves. 
Speakers risk potential loss of their intended message (indirect speech), intentionally convey wrong information (lies), and suffer inefficiencies -- all in the service of being polite.
If information transfer were the only currency in communication, politeness would be both infelicitous and undesirable.  
<!-- a cooperative speaker would find polite utterances undesirable because they are potentially misleading.  -->

A *cooperative speaker*, however, can be imagined as one who has an epistemic goal to improve the listener's knowledge state *as well as* a social goal to minimize any potential damage to the hearer's (and the speaker's own) self-image, called *face* [@Brown1987]. 
If the speaker's intended meaning contains no threat to the speaker or listener's face, then the speaker will choose to convey the meaning in an explicit and efficient manner (putting it "on the record"). 
As the degree of face-threat becomes more severe, however, a speaker will choose to be polite by producing more indirect utterances. 

Inspired by this set of ideas, we have argued that listeners think about polite speech as reflecting a tradeoff between two goals: information transfer (which we called *epistemic utility*) and face-saving [*social utility*; @yoon2016].
A speaker with a high weight on social utility will try to save her listener’s face: She hides or risks losing information in her intended message by making her utterance false to some degree.
On the other hand, a speaker with a high weight on epistemic utility prioritizes truthfulness and informativity, and she may risk a loss of the listener's (or the speaker's own) face.
These idaes were formalized in a model of pragmatic language understanding, building on the Rational Speech Act (RSA) theory [for a review, see @goodman2016].
We tested the polite RSA model (pRSA) by examining white lies.
The model captured human participants' inferences about a speaker's goals given her utterance (e.g., saying a *good* talk was "great" implies that she is being nice) and about the world given a speaker's goal (e.g., saying "great" may mean the talk was only *good* or *ok*).
People attributed the goal to be nice increasingly as the speaker's utterance was more positively biased from the true states, and inferred worse true states than the literal meaning when the speaker was described as wanting to be nice.

In the current work, we extend our framework to another polite speech act: *indirect speech*. 
<!-- White lies are one particular case of polite speech, whereby a speaker tries to save the listener's face through giving false information to some degree. -->
White lies are when a speaker tries to save the listener's face by stretching the truth.
But instead of lying, people sometimes try to be polite by being more indirect.
Through indirect speech, a speaker can express meaning that is different from the literal meaning of the utterance [@searle1975].
In this work, we focus on negation ("not"), which has the potential to be indirect.
For instance, "Mark *isn't* the cleanest person I know" may suggest that the speaker thinks Mark is *unclean* (inferred meaning) rather than not being the person Mark knows who has the greatest degree of cleanliness (literal meaning).
Negation can be used as a hedging or mitigating device to address an undesirable state that is face-threatening to the addressee [@Brown1987; @Grice1975]. <!--, and can imply that the intended meaning is worse than the vague meaning.--> 

What may lead a speaker to produce indirect remarks? 
An indirect remark may be motivated by the need to convey some face-threatening information, while being seen as the sort of person who avoids threatening others' face.
In our previous work, we described a pragmatic listener that jointy infered the world state and the goals of the speaker. 
Building on this model, we describe here a social speaker who's goal is to lead this pragmatic listener to believe the true world state *and* attribute to the speaker certain goals (e.g. avoiding face-threat).
For instance, "not amazing" does not preclude the possibility that the presentation was bad, and may be pragmatically strenthened to mean this; yet because the speaker does not choose the more direct utterance ("bad") the listener will infer that a face-threat-avoidance goal. 
Thus "not amazing" can accomplish the dual goals of conveying that the presentation was bad but that the speaker is the sort of person who would not want to make the listener feel bad by saying so.
On the other hand, if the speaker does not care about being seen as avoiding face-threat, they will produce less indirect speech.
<!--
Informationally, "not amazing" does not preclude the possibility that the presentation was bad, so the utterance is not a downright lie.
And socially, Alice tries to save Bob’s face by not being explicitly critical (e.g., not saying "it was terrible").
-->
Further, if the presentation was actually good, or even decent, the speaker will prefer to produce a directly positive remark ("It was good") in either case. 
Thus we predict more indirect speech when the true state is bad, and an interaction with the speaker's desire to be seen as avoiding face-threat. In what follows, we derive our hypotheses using our formal model and present an empirical test of the hypotheses.
<!--
Thus we predict that a speaker who wants to balance between epistemic and social goals would produce indirect speech relatively more, especially when the true state is bad. 
Importantly, we predict it is the interaction between presence of face threat (due to addressee's poor performance) and speaker's consideration of both epistemic and social goals that is predicted to lead to a greater degree of indirect speech production. In what follows, we derive our hypotheses using our formal model and present an empirical test of the hypotheses.
-->

# Computational Model

In the current work, we introduce minimal extension to our previous RSA model [pRSA; @yoon2016] to allow for speaker production of indirect remarks using negation. 

## Polite RSA

RSA models assume speakers choose utterances approximately optimally given a utility function [@Goodman2013].
pRSA posited that the speaker's utility function can be decomposed into two components.
First, *epistemic utility* ($U_{epi}$) refers to the standard, informative utility in RSA: the amount of information a *literal listener* ($L_0$) would still not know about world state $s$ after hearing a speaker's utterance $w$.
Second, *social utility* ($U_{soc}$) is the expected subjective utility of the state the listener would infer given the utterance $w$. 
The expected subjective utility is related to the intrinsic value of the state, and we use a value function ($V$) to map states to subjective utility values.
This captures the affective consequences for the listener of being in state $s$.
Finally, some speech acts might be more costly than others. 
The utility of an utterance subtracts the cost $c(w)$ from the weighted combination of the social and epistemic utilities.

$$U(w;s;  \hat{\beta}) = \beta_{epi}\cdot \ln(P_{L_0}(s \mid w)) 
\\+ \beta_{soc} \cdot \mathbb{E}_{P_{L_0}(s \mid w)}[V(s)]- C(w)$$

The speaker ($S_1$) in pRSA chooses utterances $w$ softmax-optimally given the state $s$ and his goal weights $\hat{\beta}$.
The pragmatic listener ($L_1$) jointly infers the state $s$ and the utility weights of the speaker, $\beta_{epi}$ and $\beta_{soc}$ [@GoodmanLassiter2015; @Kao2014]. 

\begin{align}
P_{L_1}(s, \hat{\beta} \mid w) &\propto P_{S_1}(w \mid s, \hat{\beta})\cdot P(s) \cdot P( \hat{\beta}) \label{eq:L1}\\
P_{S_1}(w \mid s, \hat{\beta}) &\propto \mathrm{exp}(\lambda_{1} \cdot \mathbb{E}[U(w; s;  \hat{\beta})]) \label{eq:S1}\\
P_{L_0}(s \mid w) &\propto [[w]](s) \cdot P(s) \label{eq:L0}
\end{align}

Within our experimental domain, we assumed there were five possible states of the world corresponding to the value placed on a particular referent (e.g., rating deserved by the presentation the speaker is commenting on, akin to a Yelp rating): $S = \{s_{1}, ...,  s_{5}\}$. 
We assume a uniform prior distribution over possible states of the world.
The states have subjective numerical values $V(s_{i}) = \alpha \cdot i$, where $\alpha$ is a free parameter.
$[[w]](s)$ corresponds to the lexical meaning of the utterance $w$ (e.g., "good") when applied to state $s$. 
We gather independent ratings for these literal meanings.

## Extensions to pRSA

The current work builds on pRSA by adding three simple but key components to predict indirect remark production.

First, we extend the utterance alternatives to include negation.
Previously we considered five possible utterances: {It was *terrible*, *bad*, *okay*, *good*, and *amazing*}, all direct assertions of specific states (e.g., "It was amazing" would be true for the state of 5 but untrue for the states of 1 or 2).
Now the speaker may say, {It *wasn't* terrible, bad, okay, good, and amazing}.
These utterances indirectly address the referent by negating certain state.

Second, we assume that it is more costly to say utterances with negation \mht{cite costly negation}.
In our full data analysis, we put a prior on this cost parameters and infer it's likely values from the data.

Third, we extende the recursive reasoning in the model. 
For our experiment, we consider the pragmatic speaker ($S_2$) who chooses an utterance based on the pragmatic listener model (Eq. \ref{eq:L1}), thinking about the state as well as goal weights that the pragmatic listener will infer.

$$P_{S_2}(w \mid s, \hat{\beta})\propto \mathrm{exp}(\lambda_{2} \cdot \ln(P_{L_1}(s,  \hat{\beta} \mid w)) - C(w))$$

In addition to these extensions, we simplify from the @yoon2016 model by including only a single mixture parameter $\phi$ governing the extent to which the speaker is being informative vs. face saving: $\beta_{epi} = \phi$, $\beta_{soc} = 1 - \phi$.
\mht{note? (or discuss) this parametrization doesn't have "antisocial" goals}.
We implemented this model using the probabilisitic programming language WebPPL [@dippl]\footnote{A complete implementation of the model, links to the experiments, raw data and analyses can be found at \url{https://github.com/ejyoon/cogsci2017}.}.

<!-- ($w \sim Unif(1,5)$) from data in each experiment. \ejy{FIXME: phi mixture weight.}  -->

In the next section, we explore the model's predictions for speaker productions of indirect speech with negation vs. direct speech with no negation.
<!-- We compare these model predictions against empirical data in speaker production experiment, where we examine people's expectations for production of utterances $u$ given a true state and a speaker's goal.  -->
<!-- We confirm that both the model predictions and empirical findings are broadly consistent with our hypothesis that indirect speech reflects a greater balance between epistemic and social goals.  -->

# Model predictions

Before describing our experimental data, we derive predictions from the pRSA model. In these initial simulations, we use fixed goal weights and parameters -- in later fits, we will derive these parameters from the data using Bayesian data analysis. Since the model requires measurements of literal semantics (i.e., what "good" means on a given dimension), we first describe these measurements and then give model predictions using them.

## Semantic measurement

We probed judgments of literal meanings of the target words assumed by our model and used in all our experiments. 


```{r expt1_results, fig.env = "figure*", fig.pos = "t", fig.width=6, fig.height=2, fig.align = "center", fig.cap = "Semantic measurement results. Proportion of acceptances of utterance types (shown in different colors) combined with target words (shown in different facets) given the true state represented on a scale of hearts. Error bars represent 95\\% confidence intervals."}
# img <- png::readPNG("figs/lit_sem.png")
# grid::grid.raster(img)

ms <- read_csv("../../../experiment/data_analysis/data/literalSemantics_wNeg.csv") %>%
  mutate(positivity = factor(as.numeric(grepl("yes", utterance)),
                             levels = c(0, 1),
                             labels = c("it wasn't ~","it was ~"))) %>%
  mutate(utterance = substring(utterance, 5)) %>%
  mutate(utterance = ordered(utterance, 
                             levels = c("terrible", "bad", "okay", "good", "amazing")))  %>%
  group_by(positivity, state, utterance, subid) %>%
  summarize(
            judgment = mean(judgment, na.rm=TRUE)
          ) %>%
  group_by(positivity, state, utterance) %>%
  multi_boot_standard(column = "judgment") %>%
  mutate(judgment = mean)

qplot(state, judgment,
      colour = positivity,
      data=ms) +
  geom_line(aes(group=positivity)) +
  facet_grid(.~utterance) +
  xlab("state (1=worst)") +
  ylab("proportion acceptances") +
  geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper,width=.1)) +
  scale_color_solarized(guide_legend(title="")) +
  ggthemes::theme_few()
```

```{r model_pred_negNoneg, fig.env = "figure*", fig.pos = "t", fig.width=6, fig.height=3, fig.align = "center", fig.cap = "Schematic model predictions (left), experimental results (center) and fitted model predictions (right) for average proportion of negation produced among all utterances, given true states (x-axis) and goals (colors)."}
img <- png::readPNG("figs/exptModNeg.png")
grid::grid.raster(img)
```

### Materials, methods, and results 

25 participants with IP addresses in the United States were recruited on Amazon's Mechanical Turk. We used 13 different context items that were previously used in @yoon2016, in which someone evaluated a performance of some kind. For example, in one of the contexts, Bob saw a presentation, and Bob's feelings toward Ann's cake (*true state*) were shown on a scale out of five hearts (e.g., two out of five hearts filled in red color). The question of interest was "Do you think Bob thought the presentation was / wasn't X?" and participants responded by choosing either "no" or "yes." The target could be one of five possible words: *terrible*, *bad*, *okay*, *good*, and *amazing*, giving rise to ten different possible utterances (with negation or no negation). Each participant read 50 scenarios, depicting every possible combination of states and utterances. The order of context items was randomized, and there were a maximum of four repeats of each context item per participant. For this and subsequent experiments, we analyzed the data by collapsing across context items. 

For each utterance-state pair, we computed the posterior distribution over the semantic weight (i.e., how consistent X utterance is with Y state) assuming a uniform prior over the weight.
Meanings of the words as judged by participants were as one would expect (see Figure 1). 
We used the fraction of participants that endorsed utterance $w$ for state $s$ to set informative priors to infer posterior credible values of the literal meanings from data in the speaker production experiment.

## Model parameters and predictions

We explore pRSA speaker mode predictions by assuming particular values to the parameters.
Recall that $\phi$ is the parameter governing the mixture of epistemic and social utilities.
We explore 3 hypothetical speakers (corresponding to 3 different mixture parameter weights): 
(a) a speaker who wants to maximally convey information ($\phi = 0.9$)
(b) a speaker who wants to make the listener feel good ($\phi = 0.1$)
(c) a speaker who wants to *both* convey information and make the listener feel good ($\phi = 0.5$).^[
In addition, the model has a few parameters not of theoretical interest.
For the purposes of generating model predictions *a priori*, we assign values to these parameters consistent with the previous litearture with this class of models: the speaker optimality parameter ($\lambda_{1}$ assigned to 2); the pragmatic speaker optimality parameter ($\lambda_{2}$ to 2); the value scale parameter ($\alpha$ to 1) in the utility function; and the parameter governing the cost of producing a negation ($C(u)$ to 2).
]

Figure 2 (left) shows the speaker's production probabilities associated with producing an indirect speech act (i.e., an utterance with negation) for the three different speakers as the true state of the world is varied.
We see, consistent with our intuition, that indirect speech was relatively more preferred in bad states than in good states.
As well, we see higher probability of negation production for the speaker who wants to achieve both goals (truthful and informative) relative to each goal independently.
Indirect speech doesn't convey that much information and so the informative speaker (a) would disprefer it.
Relatedly, the speaker who only wants to make the listener feel good should signal unambiguously a better state than they are in.
It is only when the speaker tries to balance both goals that the indirect speech act (i.e., negation) is preferred.

# Speaker production experiment

To compare against our model predictions, we measured participants' predictions for the most likely utterance produced by the speaker ($u$), given a description of the true state of the world. For example, given that the speaker wanted to make the listener feel good but felt that a poem deserved 2 out of 5 hearts, what would she say? Critically, the contexts indicated face threats toward the listener, as the speaker's utterance was a direct evaluation of the listener's performance. We hypothesized that when there is no tradeoff between informativity and face-threat avoidance (i.e. when the addressee's performance was great), speakers should use truthful and face-saving direct remarks ("[Your poem] was amazing") regardless of their described goals. However, when there was a conflict between the epistemic and social goals (i.e., when the addressee's performance is poor), a speaker who tried to compromise between both goals would use vague indirect remarks ("[Your poem] wasn't terrible") more often than direct face-threatening remarks ("[Your poem] was bad"; preferred by an informative speaker) or direct face-saving remarks ("[Your poem] was good"; preferred by face-saving speaker). Our hypothesis and method were pre-registered prior to data collection on the Open Science Framework (\url{http://osf.io/b73dm}). 

## Method

### Participants

202 participants with IP addresses in the United States were recruited on Amazon's Mechanical Turk.

### Stimuli and Procedure

As in the semantics measurements above, we used scenarios in which a person (e.g., Ann) gave some performance and asked for another person (e.g., Bob)'s opinion on the performance. Additionally, we provided information on the speaker Bob's goal -- *to make Ann feel good*, or *to give as accurate and informative feedback as possible*, or both -- and the true state -- how Bob actually felt Ann's performance (e.g., 2 out of 5 hearts). Each participant read 15 scenarios, depicting every possible combination of goals and states. The order of context items was randomized, and there were a maximum of two repeats of each context item per participant.

```{r expt2_screen, fig.env = "figure", fig.pos = "H", fig.width=3.5, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Example of a trial in Experiment 1."}
img <- png::readPNG("figs/expt2_screen.png")
grid::grid.raster(img)
```

Each scenario was followed by a question that read, "If Bob wanted *to make Ann feel good* (or *to give accurate and informative feedback*, or *BOTH make Sarah feel good AND give accurate and informative feedback*), what would Bob be most likely to say?" Participants indicated their answer by choosing one of the options on the two dropdown menus, side-by-side, one for choosing between *was* vs. *wasn't* and the other for choosing among *terrible*, *bad*, *okay*, *good*, and *amazing* (see Figure 3).

## Behavioral results

```{r expt2_results, fig.env = "figure*", fig.pos = "t", fig.width=7, fig.height=6, fig.align = "center", fig.cap = "Experimental results (\"experiment\" rows) and model predictions (\"model\" rows) for speaker production. Proportion of utterances chosen (utterance type -- direct vs. indirect -- on x-axis and words shown in different colors) given the true state (columns) and speaker goals (rows). Error bars represent 95\\% confidence intervals for the data and 95\\% highest density intervals for the model."}
img <- png::readPNG("figs/exptModUtt.png")
grid::grid.raster(img)
```

Full results are shown in Figure 4. 
Our hypotheses for utterance production by speakers with different goals were borne out.  
For good states (4 and 5 hearts), positive direct remarks were judged to be the most likely utterances across all three goal conditions. 
For less-than-perfect, but still decent states, there was a greater degree of expectation of white lies (e.g., "It was amazing" for 4 hearts) given a social goal. 
For bad states (1 and 2 hearts), as we predicted, there were more instances of expected indirect remarks overall across all goal conditions given bad states. 
Critically, speakers with goals to be both informative and socially considerate produced more indirect remarks than were observed in the other two goal conditions (Figure 2, center). 

<!-- Thus, these results indicated that a speaker who considers both informative and social goals, and thus is in want of a compromise between the two, is expected to produce relatively more indirect remarks. -->

## Model predictions

### Model fitting

In this experiment, participants were told true states and what speakers' intentions were (e.g., Bob wanted to make Alice feel good). We assume that the intention descriptions conveyed the weights {$\beta_{epi}$, $\beta_{soc}$} that the speaker was using. We put uninformative priors on these weights ($\beta$ ~ Uniform(0,1)) and inferred their credible values separately for each goal condition ("wanted to X") using Bayesian data analytic techniques [@LW2014]. We also used the fraction of participants that endorsed utterance $w$ for state $s$ to set informative priors to infer posterior credible values of the literal meanings from data.

```{r model_param}
load("../../../model/results/cogsci17/bda-s2-mcmc80k-x4-params.RData")

param_summary <- bda.params %>%
  group_by(param) %>%
  summarize(MAP = estimate_mode(val),
            ci_lower = hdi_lower(val),
            ci_upper = hdi_upper(val))
```

There were four additional parameters of the model: the speaker optimality parameter ($\lambda_{S_1}$); the pragmatic speaker optimality parameter ($\lambda_{S_2}$); the value scale parameter ($\alpha$) in the utility function; and the cost parameter ($C(u)$). We put uninformative priors on these ($\lambda_{S_1}$ ~ Uniform(0,20); $\lambda_{S_2}$ ~ Uniform(0,5); $\alpha$ ~ Uniform(0,5); $C(w)$ ~ Uniform(1,10)) and infer their posterior credible values from the data. We ran 4 MCMC chains for 80,000 iterations, discarding the first 40,000 for burnin. The Maximum A-Posteriori (MAP) estimate and 95% Highest Probability Density Interval (HDI) for $\lambda_{S_1}$ are `r round(param_summary$MAP[3], 2)` [`r round(param_summary$ci_lower[3], 2)`, `r round(param_summary$ci_upper[3], 2)`]; for $\lambda_{S_2}$ `r round(param_summary$MAP[4], 2)` [`r round(param_summary$ci_lower[4], 2)`, `r round(param_summary$ci_upper[4], 2)`]; for $\alpha$ `r round(param_summary$MAP[1], 2)` [`r round(param_summary$ci_lower[1], 2)`, `r round(param_summary$ci_upper[1], 2)`]; and for $C(w)$ `r round(param_summary$MAP[2], 2)` [`r round(param_summary$ci_lower[2], 2)`, `r round(param_summary$ci_upper[2], 2)`]. To generate utterance predictions, given our cognitive model and the inferred parameters, we evaluated the posterior predictive distribution, marginalizing out all parameters. 

### Results

```{r model_param2}
load("../../../model/results/cogsci17/bda-s2-mcmc80k-x4-goalWeights.RData")

weights_summary <-   bda.goalWeights %>% 
  group_by(param, goal) %>%
  summarize(
    MAP = estimate_mode(val),
            ci_lower = hdi_lower(val),
            ci_upper = hdi_upper(val))
```

The inferred weights for each goal condition were largely as expected: For the "wanted to give informative feedback" (*informative*) condition, the model put a moderate weight on epistemic utility (`r round(weights_summary$MAP[2], 3)`). For the "wanted to make [the listener] feel good" (*social*) condition, the model inferred that the speaker was using a moderate weight on epistemic utility (`r round(weights_summary$MAP[3], 3)`). For the "wanted BOTH to make [the listener] feel good and give informative feedback" (*both*) condition, the model assigned a weight on epistemic utility between the weights for the other two goal conditions (`r round(weights_summary$MAP[1], 3)`). Overall, the weights tended to be more biased towards prioritizing the epistemic utility. 

The predictions for the speaker's utterance were broadly consistent with the experimental findings (Figures 4 and 5). The model successfully predicted distinct patterns for each goal condition. The *informative* speaker produced direct remarks whose literal meanings mapped onto the true states (e.g. "It was terrible" given 1 heart). The *social* speaker produced remarks that were positively biased compared to the true states (e.g. "It was okay" given 2 hearts). 
<!-- The *both-goal* speaker generally produced more indirect remarks with negation than the others ("It was terrible" had the highest likelihood given 1 heart).  -->

However, when fit to the empirical data, the model did not predict the expected difference for negation production between both-goal and social conditions (Figure 2, right); though the trend was numerically correct, the effect was much smaller in the fit model than the schematic one. There are several possible explanations for this deviation. First, in our experimental data, the social speaker placed a higher weight on epistemic utility than in our schematic predictions. Thus, the particular goal descriptions we used in the experiment may have suggested that the social speaker still wanted to be informative. If this explanation holds, our argument is still valid: a balance between epistemic and social utility, rather than bias toward one utility over the other, is what predicts indirect speech production. Second, another possible cause is that participants preferred a *different kind* of indirect speech than the model -- in particular, the both-goal speaker preferred to produce "It wasn't amazing" in the schematic model predictions, whereas participants in our experiment chose "It wasn't terrible." This discrepancy between the two remarks is interesting, because their implied meaning is similar. In a pilot experiment where participants were asked to infer the true state (number of hearts) from an utterance, "It wasn't amazing" and "It wasn't terrible" were very similar (~2 hearts). 

Overall, however, the posterior predictions of the fit model explained almost all of the variance in the average data $r^2$(15) = 0.962 (Figure 5). Thus, the model results support our hypothesis that the combination of epistemic and social utilities explain politeness behavior across a wide range of conditions. 

```{r expt2_model, fig.env = "figure", fig.pos = "h", fig.width=3, fig.height=3, fig.align = "center", fig.cap = "Full distribution of human responses vs. model predictions. Error bars represent 95\\% confidence intervals for the data and 95\\% highest density intervals for the model."}
img <- png::readPNG("figs/exptModCor.png")
grid::grid.raster(img)
```

# Discussion

Why are we polite? Here we explored a formal instantiation of the hypothesis that two conflicting speaker goals -- epistemic and social -- can be used to explain a range of polite behavior, including white lies and indirect speech acts using negation. Our model predicted that speakers should produce more indirect remarks in cases of greater face threat (poorer performance) and in cases where speakers wanted to be both informative and nice. Our experimental data confirmed these predictions. The model's overall fit to the data was very strong, although it did not show the predicted dominance of indirect speech for the both-goal speaker at low states. Whether this discrepancy between the initial and data-fitted predictions was due to variation in goal weight based on experimental scenarios or a discrepancy in preferences for paricular utterances is a question for future work.

An important contribution of this work is in showing the generalizability of our formal model (polite RSSA) to the case of indirect speech acts. Can the model be extended to other polite speech phenomena? One significant factor to take into account will be speakers' self-presentation: Not only do speakers want to save the listener's face, but they also want to save their *own* face. In future work we hope to examine how our model's utilities can be extended to capture the speaker's desire to appear polite, genuine, and modest. Using the model to explore other kinds of polite speech such as indirect requests ["Would you mind closing the window?"; @clark1980], agreeable self-presentations (e.g. modesty; "I didn't do too well on my test"), and manifestations of polite speech in different cultures [e.g., @holtgraves1990] are also important future directions.

In sum, our formal model and experimental work represent an advance in polite speech understanding. With a minimal extension to our existing model, we were able to capture subtle patterns in people's inferences about indirect speech production. Our empirical findings suggest that neither epistemic nor social motives alone motivate indirect speech; instead, the need for indirect speech results from the conflict between these two. These findings provide strong support for a utility-theoretic framing of politeness, and suggest new directions in understand pragmatic language use in social contexts.

# Acknowledgments

This work was supported by NSF grant BCS #1456077 to MCF, ONR grant N00014-13-1-0788 and a James S. McDonnell Foundation Scholar Award to NDG, NSF Graduate Research Fellowship DGE-114747 to MHT, and NSERC post-graduate doctoral scholarship PGSD3-454094-2014 to EJY.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
